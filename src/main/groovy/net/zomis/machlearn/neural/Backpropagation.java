package net.zomis.machlearn.neural;

import java.util.*;
import java.util.function.Consumer;
import java.util.stream.DoubleStream;

public class Backpropagation {

    private final double learningRate;
    private final int iterations;
    private int logRate = Integer.MAX_VALUE;
    private boolean costFunctionCheck;

    public Backpropagation(double learningRate, int iterations) {
        if (learningRate <= 0 || learningRate > 1) {
            throw new IllegalArgumentException("Learning rate must be in range (0..1]");
        }
        this.learningRate = learningRate;
        this.iterations = iterations;
    }

    public NeuralNetwork backPropagationLearning(Collection<LearningData> examples, NeuralNetwork network) {
        return backPropagationLearning(examples, network, initializeRandom(new Random()));
    }

    public static Consumer<NeuralNetwork> initializeRandom(Random random) {
        return network ->
            network.links().forEach(it -> it.setWeight(random.nextDouble() / 2 - 0.25));
    }

    public NeuralNetwork stohasticGradientDescent(List<LearningData> examples,
          NeuralNetwork network, Consumer<NeuralNetwork> weightsInitialization,
          Random random, int targetIterations) {
        int[] layerSizes = network.getLayers().stream().mapToInt(NeuronLayer::size).toArray();

        if (weightsInitialization != null) {
            weightsInitialization.accept(network);
        }

        Collections.shuffle(examples, random);

        double[][] deltas = createDeltasArray(network);

        double previousCost = Double.MAX_VALUE;
        int iterations = 0;
        while (true) {
            zero(deltas);

            iterations++;
            double cost = 0;
            for (LearningData data : examples) {
                learnFromExample(network, data, deltas, null);
                cost += costFunction(network, data);
            }

            double regularizationTerm = 0;
            cost = (-cost / examples.size()) + regularizationTerm;

            if (iterations % logRate == 0) {
                System.out.printf("Stochastic BackPropagation %s iteration %d : cost %f%n",
                        Arrays.toString(layerSizes), iterations, cost);
            }
            if (iterations > targetIterations) {
                break;
            }
        }
        return network;
    }

    public static double[][] createDeltasArray(NeuralNetwork network) {
        double[][] deltas = new double[network.getLayerCount() - 1][];
        for (int layeri = 0; layeri < network.getLayerCount() - 1; layeri++) {
            NeuronLayer layer = network.getLayer(layeri + 1);
            deltas[layeri] = new double[layer.size()];
        }
        return deltas;
    }

    public void learnFromExample(NeuralNetwork network, LearningData data, double[][] deltas,
          double[][][] capitalDeltas) {
        /* Propagate the inputs forward to compute the outputs */
        int neuronIndexInLayer = 0;
        for (Neuron neuron : network.getInputLayer()) {
            neuron.setOutput(data.getInput(neuronIndexInLayer++));
        }
        for (int layerIndex = 1; layerIndex < network.getLayerCount(); layerIndex++) {
            NeuronLayer layer = network.getLayer(layerIndex);
            for (Neuron node : layer) {
                node.process();
            }
        }

        /* Using y(t) compute delta(L) = a(L) - y(t) */
        double[] expectedOutput = data.getOutputs();
        neuronIndexInLayer = 0;
        for (Neuron neuron : network.getOutputLayer()) {
            double neuronError = neuron.getOutput() - expectedOutput[neuronIndexInLayer];
            neuronError = neuronError * data.weight;
            deltas[network.getLayerCount() - 2][neuronIndexInLayer] = neuronError;
            neuronIndexInLayer++;
        }

        /* Propagate deltas backward from output layer to input layer
         * Compute delta(L-1), delta(L-2), ..., delta(2)
         * using delta(l) = ((theta(l)' * delta(l+1) .* a(l) .* (1-a(l)) */
        for (int layerIndex = network.getLayerCount() - 2; layerIndex >= 1; layerIndex--) {
            final int layerIdx = layerIndex;
            NeuronLayer layer = network.getLayer(layerIndex);
            for (int nodei = 0; nodei < layer.size(); nodei++) {
                Neuron neuron = layer.getNeurons().get(nodei);
                double sum = neuron.getOutputs().stream().mapToDouble(link ->
                        link.getWeight() * deltas[layerIdx][link.getTo().indexInLayer]
                ).sum();
                double gPrim = neuron.getOutput() * (1 - neuron.getOutput());
                double delta = sum * gPrim;
                deltas[layerIndex - 1][nodei] = delta;
                // println "deltas[$layerIndex - 1][$nodei] = $sum * $gPrim = $delta"
            }
        }

        /* capitalDelta(l, i, j) += a(l, j) * delta(l+1, i) */
        for (int layerIndex = 0; layerIndex < network.getLayerCount() - 1; layerIndex++) {
            NeuronLayer layer = network.getLayer(layerIndex);
            NeuronLayer nextLayer = network.getLayer(layerIndex + 1);
            for (int i = 0; i < nextLayer.getNeurons().size(); i++) {
                for (int j = 0; j < layer.getNeurons().size() + 1; j++) {
                    /* capitalDeltas[L][i][j] =
                     * delta between layer L and layer L + 1, including input layer, excluding ooutput layer
                     * node i in layer L+1
                     * if j == 0, bias unit in layer L
                     * otherwise, node j (1-indexed) in layer L
                     **/
                    double wantedDeltaValue = deltas[layerIndex][i];
                    double value = 1;
                    if (j > 0) {
                        value = layer.getNeurons().get(j-1).getOutput();
                    }

                    if (capitalDeltas == null) {
                        double capitalD = value * wantedDeltaValue;
                        NeuronLink link = nextLayer.getNeurons().get(i).getInputs().get(j);
                        link.setWeight(link.getWeight() - learningRate * capitalD);
                    } else {
                        capitalDeltas[layerIndex][i][j] += value * wantedDeltaValue;
                    }
                }
            }
        }

    }

    public NeuralNetwork backPropagationLearning(Collection<LearningData> examples,
             NeuralNetwork network, Consumer<NeuralNetwork> weightsInitialization) {
        int[] layerSizes = network.getLayers().stream().mapToInt(NeuronLayer::size).toArray();
//        inputs: examples, a set of examples, each with input vector x and output vector y
//        network , a multilayer network with L layers, weights wi,j , activation function g

        // local variables: Î”, a vector of errors, indexed by network node
        int iterations = 0;

        if (weightsInitialization != null) {
            weightsInitialization.accept(network);
        }
        double[][] deltas = new double[network.getLayerCount() - 1][];
        for (int layeri = 0; layeri < network.getLayerCount() - 1; layeri++) {
            NeuronLayer layer = network.getLayer(layeri + 1);
            deltas[layeri] = new double[layer.size()];
        }

        double[][][] capitalDeltas = new double[network.getLayerCount() - 1][][];
        for (int layerIndex = 0; layerIndex < network.getLayerCount() - 1; layerIndex++) {
            /* capitalDeltas[L][i][j] =
             * delta between layer L and layer L + 1, including input layer, excluding ooutput layer
             * node i in layer L+1
             * if j == 0, bias unit in layer L
             * otherwise, node j (1-indexed) in layer L
             **/
            NeuronLayer layer = network.getLayer(layerIndex + 1);
            capitalDeltas[layerIndex] = new double[layer.size()][];
            for (int i = 0; i < layer.getNeurons().size(); i++) {
                Neuron neuron = layer.getNeurons().get(i);
                capitalDeltas[layerIndex][i] = new double[neuron.getInputs().size()];
            }
        }

        double previousCost = Double.MAX_VALUE;
        while (true) {
            zero(deltas); // TODO: Should the `deltas` array be zeroed here? Might not need zeroing
            zero(capitalDeltas);

            iterations++;
            double cost = 0;
            for (LearningData data : examples) {
                learnFromExample(network, data, deltas, capitalDeltas);
                cost += costFunction(network, data);
            }

            double totalChange = 0;
            /* Update every weight in network using deltas */
            for (int l = 0; l < capitalDeltas.length; l++) {
                NeuronLayer nextLayer = network.getLayer(l + 1);
                double totalLayerChange = 0;
                for (int i = 0; i < capitalDeltas[l].length; i++) { // index in nextLayer
                    for (int j = 0; j < capitalDeltas[l][i].length; j++) { // index in `layer`, or 0 for bias unit
                        double regularization = 0;
                        NeuronLink link = nextLayer.getNeurons().get(i).getInputs().get(j);
                        double capitalD = 1d / examples.size() * (capitalDeltas[l][i][j] + regularization);
                        // double gradientCheck = gradientCheck(link, network, examples)
                        totalChange += Math.abs(capitalD);
                        totalLayerChange += Math.abs(capitalD);
                        // println "$gradientCheck vs $capitalD = ${Math.abs(gradientCheck - capitalD)}"

                        link.setWeight(link.getWeight() - learningRate * capitalD);
                    }
                }
                // println "Layer $l change $totalLayerChange"
            }


            double regularizationTerm = 0;
            cost = (-cost / examples.size()) + regularizationTerm;

            if (costFunctionCheck) {
                if (cost > previousCost) {
                    throw new IllegalStateException("Cost function increased from " + previousCost + " to " + cost +
                            ": Network not learning correctly.");
                }
                previousCost = cost;
            }

            if (iterations % logRate == 0) {
//                DoubleSummaryStatistics data = Arrays.asList(deltas).stream()
//                    .flatMapToDouble(Arrays::stream)
//                    .summaryStatistics();
//                DoubleSummaryStatistics capitalDeltaData = Arrays.asList(capitalDeltas).stream()
//                        .flatMap(it -> Arrays.asList(it).stream())
//                        .flatMapToDouble(Arrays::stream).summaryStatistics();
//                System.out.printf("BackPropagation %s iteration %d : %s %s cost %s%n",
//                        Arrays.toString(layerSizes), iterations, data, capitalDeltaData, cost);
                System.out.printf("BackPropagation %s iteration %d : change %f, cost %f%n",
                        Arrays.toString(layerSizes), iterations, totalChange, cost);
            }
            if (iterations > this.iterations) {
                break;
            }
        }
        return network;
    }

    static double gradientCheck(NeuronLink link, NeuralNetwork network, Collection<LearningData> datas) {
        double originalWeight = link.getWeight();
        final double EPSILON = 0.0001;

        link.setWeight(originalWeight + EPSILON);
        double costPlus = costFunction(network, datas);

        link.setWeight(originalWeight - EPSILON);
        double costMinus = costFunction(network, datas);

        // println "Cost plus $costPlus cost minus $costMinus"
        link.setWeight(originalWeight);

        return (costPlus - costMinus) / (2 * EPSILON);
    }

    private static void zero(double[][] doubles) {
        for (double[] layer : doubles) {
            Arrays.fill(layer, 0);
        }
    }

    private static void zero(double[][][] doubles) {
        for (double[][] layer : doubles) {
            zero(layer);
        }
    }

    private static double costFunction(NeuralNetwork network, Collection<LearningData> datas) {
        double sum = 0;
        for (LearningData data : datas) {
            network.run(data.getInputs());
            sum += costFunction(network, data);
        }
        // println "costFunction sum $sum training set ${datas.size()}"
        return (-1d / datas.size()) * sum;
    }

    private static double costFunction(NeuralNetwork network, LearningData learningData) {
        double sum = 0;
        double[] out = learningData.getOutputs();

        NeuronLayer outputLayer = network.getOutputLayer();
        for (int i = 0; i < out.length; i++) {
            double expected = out[i];
            double actual = outputLayer.getNeurons().get(i).getOutput();
            sum += logisticCost(expected, actual);
        }
        return sum;
    }

    private static double logisticCost(double expected, double actual) {
        return expected * Math.log(actual) + (1 - expected) * Math.log(1 - actual);
    }

    public Backpropagation setLogRate(int logRate) {
        this.logRate = logRate;
        return this;
    }

    public int getLogRate() {
        return logRate;
    }

    public static Consumer<NeuralNetwork> initializeRandomOffset(Random random, double v) {
        return network ->
            network.links().forEach(it -> it.setWeight(it.getWeight() + random.nextDouble() * v * 2 - v));
    }

    public void setCostFunctionCheck(boolean costFunctionCheck) {
        this.costFunctionCheck = costFunctionCheck;
    }
}
